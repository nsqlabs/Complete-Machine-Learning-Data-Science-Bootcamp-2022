{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "185aed68-d1dc-4062-9796-60955a601471",
   "metadata": {},
   "source": [
    "# 1) What is the goal of Machine Learning?\n",
    "\n",
    "The goal of machine learning is to make computers act more and more like humans. The more they act like humans, the more helpful they are for humans!\n",
    "\n",
    "![](https://slideplayer.com/slide/15542840/93/images/2/The+goal+of+machine+learning.jpg)\n",
    "\n",
    "Computers were brought into this world to make completing tasks more efficient for humans.\n",
    "\n",
    "## Types of ml problems\n",
    "\n",
    "First, we should clarify for what types of problems we don't need ML to solve (since AI isn't the answer to everything): when a simple hand-coded instruction-based systen will work. For example, if you want to create your favorite dish, if you already know what you need in order to create the result and how to get there, you shouldn't and it wouldn't make sense to use ML to gather the processes.\n",
    "\n",
    "Main types of machine learning:\n",
    "\n",
    "- Supervised learning.\n",
    "- Unsupervised learning\n",
    "- Transfer learning\n",
    "- Reinforcement learning.\n",
    "\n",
    "### Supervised learning\n",
    "\n",
    "![](https://miro.medium.com/max/1164/1*589X2eXJJkatGRG-z-s_oA.png)\n",
    "\n",
    "### Unsupervised Learning\n",
    "\n",
    "![](https://www.newtechdojo.com/wp-content/uploads/2018/03/How-unsupervised-machine-Learning-works.jpg)\n",
    "\n",
    "### Transfer Learning\n",
    "\n",
    "![](https://miro.medium.com/max/1000/0*xNjEPIZmPvKeqss6)\n",
    "\n",
    "### Reinforcement Learning\n",
    "\n",
    "![](https://bigdata-madesimple.com/wp-content/uploads/2018/02/Machine-Learning-Explained3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9f0705-7903-42e9-921e-01a3b6cde13d",
   "metadata": {},
   "source": [
    "# 2) AI/Machine Learning/Data Science\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://corpnce.com/wp-content/uploads/2019/08/AI-Ml-Dl-Ds.jpg\" width=600 />\n",
    "</center>\n",
    "\n",
    "- **Artificial Intelligence**: human intelligence exhibited by machines.\n",
    "    - Narrow AI - Machines can be just as good or even better than humans at certain tasks. Ex: detecting heart disease, playing chess, etc. Narrow AI is only good at one specific task extremely well.\n",
    "    - Artifical General Intelligence (AGI) - Extremely good at many human tasks (we are approaching this era soon)\n",
    "\n",
    "- **Machine Learning** - a subset of AI. It's an approach to try and achieve AI through systems that want to find patterns through a set of data. Computers can do things without us saying, \"do this, then do that\". Stanford describes ML as the science of getting machines to act without humans specifying instructions.\n",
    "- **Deep Learning** - Techniques for implementing machine learning. (also: deep neural networks)\n",
    "- **Data Science** - Simply put, analyzing data. There's a lot of overlap w. ML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea546da1-e665-4ec7-a2d2-42ed58c0dab3",
   "metadata": {},
   "source": [
    "# 3) How did we get to Machine Learning?\n",
    "\n",
    "![](https://miro.medium.com/max/1024/1*JjegBW6yFNZ_C03caU7-PQ.png)\n",
    "\n",
    "We first used spreadsheets like excel to generate data and put it in an excel file to make business decisions. As companies got more idea, we created this idea of relational databases. We needed a better way to organize and understand things from data. Thus, came MySQL: this helped us read, write, and understand data of many different types. Then, in 2000s, we created this idea of \"big data\" since FB, Google, Twitter needed to store way more precise data for their customers. Then after, NoSQL + MongoDB came along to help us manage even more meta data.\n",
    "\n",
    "Machine Learning came along to automate and help us make data-driven decisions more efficiently. This was due to the growth in data and the improvements of CPU, GPU, and computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc77aac-9e77-4cc0-a3aa-580e34e39063",
   "metadata": {},
   "source": [
    "# 4) A data science framework\n",
    "\n",
    "![](https://camo.githubusercontent.com/45d5c52fc8f22090fdbc0c1962b5929f829c1c63d18e3bc87694bd464c572978/68747470733a2f2f636c6f75642d71756d6669727935752e76657263656c2e6170702f3073637265656e5f73686f745f323032302d31302d32325f61745f362e34392e34305f706d2e706e67)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7de0c5-5800-437f-9584-97fbd6b78be2",
   "metadata": {},
   "source": [
    "## II) Data\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://miro.medium.com/max/1400/1*ZHn6VcrTacZRA7wQKq6pIw.jpeg\" />\n",
    "</center>\n",
    "\n",
    "![](https://assets.website-files.com/5fb24a974499e90dae242d98/60ff737f7a1aa850528e99b2_structured%20data%20unstrutured%20data%20vs%20semi%20structured%20data%20info.jpg)\n",
    "![](https://wiki.atlan.com/content/images/2019/10/structured-semi-and-unstructured.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696e4ca5-647a-4475-a546-714407003aee",
   "metadata": {},
   "source": [
    "## III) Evaluation.\n",
    "\n",
    "Machine Learning projects are based on a considerable amount of research, infinite trial and error cycles, and never enough data. None of these adjectives has anything in common with Return of Investment, profitability, predictability, which are needed by any successful business.\n",
    "\n",
    "Below is a list of metrics that I measure in Machine Learning projects:\n",
    "\n",
    "- **Time to market** — how long does it take from the moment the user wants a specific functionality to the moment it can be used in production? As an investor or Product Owner, you’ll need to know what expectations to set to your clients when it comes to releasing times. Maybe your clients will expect it fixed by the next day, but we are fixing the way the machine learns, not an algorithm or a design. More you know about this process, more you can educate your market.\n",
    "- **Training time** — how long does it take to train a machine learning model\n",
    "- **Data** — how much data and of which quality does the solution need to improve.\n",
    "- **Minimum data** — the challenge of machine learning is that you need a lot of data, but what is the minimum amount of data to have a solution that can be released to the market?\n",
    "- **Algorithm improvements when doing maintenance updates.** Keeping track of the upgrades and stages is something that can standardize and predict your development process. It also helps to give direction and in the roadmap decision making process.\n",
    "- **Number of training cycles before a solution is ready to be released.** After about three significant releases, you’ll start to see trends on how many learning cycles your model needs for a considerable version of a new feature.\n",
    "- **Performance** — how long does it take to perform a specific operation? Can the technology scale? What are the scaling points? How many users can we support at a given time, and with what cost? The product price, the sales, and the entire business strategy are depending on the answer to these questions. The stakeholders will know that they’ll have to change the business approach when they reach a certain point. On the other hand, the development team will see what technical solutions they need to research to meet the business targets.\n",
    "- **Hardware cost vs. new technology upgrade?** — Everyone wants to work with the latest technology, but does it make sense of the update? Is it really what provides most of the business value? The cost of the hardware will skyrocket with the success of your machine learning solution. That’s a given. When there is a new technology, evaluate how much you need to invest in hardware on each user threshold and what is the hardware reduction provided by software development. In most of the situations, it will be cheaper to pay for the development team to upgrade the technology that buying new GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fb88bf-ec48-4275-b0b3-77c8e1632bd3",
   "metadata": {},
   "source": [
    "### Classification metrics\n",
    "\n",
    "Classification is about predicting the class labels given input data. In binary classification, there are only two possible output classes(i.e., Dichotomy). In multiclass classification, more than two possible classes can be present. I’ll focus only on binary classification\n",
    "\n",
    "> A very common example of binary classification is spam detection, where the input data could include the email text and metadata (sender, sending time), and the output label is either “spam” or “not spam.” (See Figure) Sometimes, people use some other names also for the two classes: “positive” and “negative,” or “class 1” and “class 0.”\n",
    "\n",
    "#### Accuracy\n",
    "\n",
    "Accuracy simply measures how often the classifier correctly predicts. We can define accuracy as the ratio of the number of correct predictions and the total number of predictions.\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/800/1*R6jP_uvlkcxtQSa264N3Sw.png)\n",
    "\n",
    "When any model gives an accuracy rate of 99%, you might think that model is performing very good but this is not always true and can be misleading in some situations. I am going to explain this with the help of an example.\n",
    "\n",
    "Consider a binary classification problem, where a model can achieve only two results, either model gives a correct or incorrect prediction. Now imagine we have a classification task to predict if an image is a dog or cat as shown in the image. In a supervised learning algorithm, we first fit/train a model on training data, then test the model on testing data. Once we have the model’s predictions from the X_test data, we compare them to the true y_values (the correct labels)\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/800/1*zzR88UEu6A786mPYcRVDhQ.png)\n",
    "\n",
    "We feed the image of the dog into the training model. Suppose the model predicts that this is a dog, and then we compare the prediction to the correct label. If the model predicts that this image is a cat and then we again compare it to the correct label and it would be incorrect.\n",
    "\n",
    "We repeat this process for all images in X_test data. Eventually, we’ll have a count of correct and incorrect matches. But in reality, it is very rare that all incorrect or correct matches hold equal value. Therefore one metric won’t tell the entire story.\n",
    "\n",
    "<mark style=\"background-color: yellow;\">**Accuracy is useful when the target class is well balanced but is not a good choice for the unbalanced classes. Imagine the scenario where we had 99 images of the dog and only 1 image of a cat present in our training data. Then our model would always predict the dog, and therefore we got 99% accuracy. In reality, Data is always imbalanced for example Spam email, credit card fraud, and medical diagnosis. Hence, if we want to do a better model evaluation and have a full picture of the model evaluation, other metrics such as recall and precision should also be considered.**</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44aecbf-31b8-4731-b231-9d7829a31bd7",
   "metadata": {},
   "source": [
    "#### Confusion Matrix\n",
    "\n",
    "Confusion Matrix is a performance measurement for the machine learning classification problems where the output can be two or more classes. It is a table with combinations of predicted and actual values.\n",
    "\n",
    "> A confusion matrix is defined as thetable that is often used to describe the performance of a classification model on a set of the test data for which the true values are known.\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/800/1*_JY_jxfndH8oBI3clamifA.png)\n",
    "![](https://cdn-images-1.medium.com/max/800/0*UnezxOaQyU6Fb6D3)\n",
    "\n",
    "- True Positive: We predicted positive and it’s true. In the image, we predicted that a woman is pregnant and she actually is.\n",
    "- True Negative: We predicted negative and it’s true. In the image, we predicted that a man is not pregnant and he actually is not.\n",
    "- False Positive (Type 1 Error)- We predicted positive and it’s false. In the image, we predicted that a man is pregnant but he actually is not.\n",
    "- False Negative (Type 2 Error)- We predicted negative and it’s false. In the image, we predicted that a woman is not pregnant but she actually is.\n",
    "\n",
    "**Some other metrics of the confusion matrix:**\n",
    "\n",
    "1. **Precision** — Precision explains0 **how many of the correctly predicted cases actually turned out to be positive. Precision is useful in the cases where False Positive is a higher concern than False Negatives.** The importance of Precision is in music or video recommendation systems, e-commerce websites, etc. where wrong results could lead to customer churn and this could be harmful to the business.\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/800/0*p1t9CzwpaOXxsx4l.png)\n",
    "\n",
    "2. **Recall (Sensitivity)** — Recall explains **how many of the actual positive cases we were able to predict correctly with our model. It is a useful metric in cases where False Negative is of higher concern than False Positive.** It is important in medical cases where it doesn’t matter whether we raise a false alarm but the actual positive cases should not go undetected!\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/800/0*XgGoMQLlGGDgpzYa.png)\n",
    "\n",
    "3. **F1 Score** — It gives a combined idea about Precision and Recall metrics. It is maximum when Precision is equal to Recall.\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/800/0*tu5x_GEgs-iRpJ9H)\n",
    "\n",
    "> The F1 score punishes extreme values more. F1 Score could be an effective evaluation metric in the following cases:\n",
    "> - When FP and FN are equally costly.\n",
    "> - Adding more data doesn’t effectively change the outcome\n",
    "> - True Negative is high"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180ae3bc-4de2-4e48-be68-6ed7fa8aced7",
   "metadata": {},
   "source": [
    "## IV) Features\n",
    "\n",
    "Features are nothing but the **independent variables in machine learning models**. What is required to be learned in any specific machine learning problem is a set of these features (independent variables), coefficients of these features, and parameters for coming up with appropriate functions or models (also termed as hyperparameters). The following represents a few examples of what can be termed as features of machine learning models:\n",
    "\n",
    "- A model for predicting the risk of cardiac disease may have features such as the following:\n",
    "    - Age\n",
    "    - Gender\n",
    "    - Weight\n",
    "    - Whether the person smokes\n",
    "    - Whether the person is suffering from diabetic disease, etc.\n",
    "- A model for predicting whether the person is suitable for a job may have features such as the education qualification, number of years of experience, experience working in the field etc\n",
    "- A model for predicting the size of a shirt for a person may have features such as age, gender, height, weight, etc.\n",
    "\n",
    "Features can be in the form of raw data that is very straightforward and can be derived from real-life as it is. However, not all problems can be solved using raw data or data in its original form. Many times, they need to be represented or encoded in different forms. For example, a color can be represented in RGB format or HSV format. Thus, a color can have two different representations or encodings. And, both of these representations or encodings can be used to solve different kinds of problems. Some tasks that may be difficult with one representation can become easy with another. For example, the task “select all red pixels in the image” is simpler in the RGB format, whereas “make the image less saturated” is simpler in the HSV format. \n",
    "\n",
    "> Machine-learning models are all about finding appropriate representations / features for their input data—transformations of the data that make it more amenable to the task at hand, such as a classification task.\n",
    "\n",
    "In case of machine learning, it is responsibility of data scientists to hand-craft some useful representations / features from the given data set. In case of deep learning, the feature representations are learnt automatically based on the underlying algorithm. One of the most important reasons why deep learning took off instantly is that it completely automates what used to be the most crucial step in a machine-learning workflow: feature engineering\n",
    "\n",
    "The figure given below represents usage of hand-crafted representations / features and raw data in building machine learning models.\n",
    "![](https://vitalflux.com/wp-content/uploads/2020/05/Features-Key-to-Machine-Learning.png)\n",
    "\n",
    "\n",
    "- The process of coming up with features including raw or derived features is called as **feature engineering**.\n",
    "- Hand-crafted features can also be called as derived features.\n",
    "- Subsequent step is to select the most appropriate features out of these features. This is called as **feature selection.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5d5de1-fbb0-42e5-939d-f37782be0b96",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce62c35b-e341-4cee-b658-4e15d1d8e8d7",
   "metadata": {},
   "source": [
    "### The most important concept in machine learning\n",
    "\n",
    "- training set: train your model on this\n",
    "- validation set: tune your model on this\n",
    "- test set: test and compare on this\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/b/bb/ML_dataset_training_validation_test_sets.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d2acee-b096-4c50-bebe-11e6fbaba8ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3 steps to modelling\n",
    "#### A) Choosing and training a model\n",
    "\n",
    "Why are there so many machine learning techniques? The thing is that different algorithms solve various problems. The results that you get directly depend on the model you choose. That is why it is so important to know how to match a machine learning algorithm to a particular problem.\n",
    "\n",
    "\n",
    "![](https://miro.medium.com/max/1200/0*PvLaavaB-1PuCgrH.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3317ddbe-121f-40c1-913a-18ef2d2f923a",
   "metadata": {},
   "source": [
    "#### B) Tuning Data\n",
    "\n",
    "![](https://blog.floydhub.com/content/images/2018/08/Screen-Shot-2018-08-22-at-18.32.53.png)\n",
    "\n",
    "Tuning is usually a trial-and-error process by which you change some hyperparameters (for example, the number of trees in a tree-based algorithm or the value of alpha in a linear algorithm), run the algorithm on the data again, then compare its performance on your validation set in order to determine which set of hyperparameters results in the most accurate model.\n",
    "\n",
    "All machine learning algorithms have a “default” set of hyperparameters, which Machine Learning Mastery defines as “a configuration that is external to the model and whose value cannot be estimated from data.” Different algorithms consist of different hyperparameters. For example, regularized regression models have coefficients penalties, decision trees have a set number of branches, and neural networks have a set number of layers. When building models, analysts and data scientists choose the default configuration of these hyperparameters after running the model on several datasets.\n",
    "\n",
    "While the generic set of hyperparameters for each algorithm provides a starting point for analysis and will generally result in a well-performing model, it may not have the optimal configurations for your particular dataset and business problem. In order to find the best hyperparameters for your data, you need to tune them.\n",
    "\n",
    "##### Why is Model Tuning Important?\n",
    "\n",
    "Model tuning allows you to customize your models so they generate the most accurate outcomes and give you highly valuable insights into your data, enabling you to make the most effective business decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e2cc40-e129-4f53-94e5-857a0f136a95",
   "metadata": {},
   "source": [
    "#### C) Comparing models\n",
    "\n",
    "When comparing models, you want to make sure that the training set has a close evaluation to the test set.\n",
    "\n",
    "![](https://media.geeksforgeeks.org/wp-content/cdn-uploads/20190523171258/overfitting_2.png)\n",
    "\n",
    "> It's important to split the data correctly in order of being objective when evaluating. If you evaluate the model with the same data it learned it haven't learn anything but it have memorized all the answers!\n",
    "\n",
    "- Poor performance on training data means the model hasn’t learned properly and is underfitting. Try a different model, improve the existing one through hyperparameter or collect more data.\n",
    "- Great performance on the training data but poor performance on test data means your model doesn’t generalize well. Your model may be overfitting the training data. Try using a simpler model or making sure your the test data is of the same style your model is training on.\n",
    "- Another form of overfitting can come in the form of better performance on test data than training data. This may mean your testing data is leaking into your training data (incorrect data splits) or you've spent too much time optimizing your model for the test set data. Ensure your training and test datasets are kept separate at all times and avoid optimizing a models performance on the test set (use the training and validation sets for model improvement).\n",
    "- Poor performance once deployed (in the real world) means there’s a difference in what you trained and tested your model on and what is actually happening. Ensure the data you're using during experimentation matches up with the data you're using in production.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017d8cba-61a8-48a1-a436-db22c61c2edc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd833e7-fd6b-496a-af72-297f58015042",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ebab80-f175-4107-8a81-e2131a161e7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Section 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b760243d-2bac-4257-a60a-bcc15aa12a13",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Algorithm vs model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a76abb4-d013-4376-9289-470d58e6e324",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### What is an algorithm in machine learning?\n",
    "\n",
    "An “algorithm” in machine learning is a procedure that is run on data to create a machine learning “model.”\n",
    "\n",
    "> Machine learning algorithms perform “pattern recognition.” Algorithms “learn” from data, or are “fit” on a dataset.\n",
    "\n",
    "There are many machine learning algorithms.\n",
    "\n",
    "For example, we have algorithms for classification, such as k-nearest neighbors. We have algorithms for regression, such as linear regression, and we have algorithms for clustering, such as k-means.\n",
    "\n",
    "Examples of machine learning algorithms:\n",
    "\n",
    "- Linear Regression\n",
    "- Logistic Regression\n",
    "- Decision Tree\n",
    "- Artificial Neural Network\n",
    "- k-Nearest Neighbors\n",
    "- k-Means\n",
    "\n",
    "You can think of a machine learning algorithm like any other algorithm in computer science.\n",
    "\n",
    "For example, some other types of algorithms you might be familiar with include bubble sort for sorting data and best-first for searching.\n",
    "\n",
    "As such, machine learning algorithms have a number of properties:\n",
    "\n",
    "- Machine learning algorithms can be described using math and pseudocode.\n",
    "- The efficiency of machine learning algorithms can be analyzed and described.\n",
    "- Machine learning algorithms can be implemented with any one of a range of modern programming languages.\n",
    "    - For example, you may see machine learning algorithms described with pseudocode or linear algebra in research papers and textbooks. You may see the computational efficiency of a specific machine learning algorithm compared to another specific algorithm.\n",
    "\n",
    "Academics can devise entirely new machine learning algorithms and machine learning practitioners can use standard machine learning algorithms on their projects. This is just like other areas of computer science where academics can devise entirely new sorting algorithms, and programmers can use the standard sorting algorithms in their applications.\n",
    "\n",
    "You are also likely to see multiple machine learning algorithms implemented together and provided in a library with a standard application programming interface (API). A popular example is the scikit-learn library that provides implementations of many classification, regression, and clustering machine learning algorithms in Python.\n",
    "\n",
    "#### What Is a “Model” in Machine Learning?\n",
    "\n",
    "**A “model” in machine learning is the output of a machine learning algorithm run on data.**\n",
    "\n",
    "> A model represents what was learned by a machine learning algorithm.\n",
    "\n",
    "<mark>**The model is the “thing” that is saved after running a machine learning algorithm on training data and represents the rules, numbers, and any other algorithm-specific data structures required to make predictions.**</mark>\n",
    "\n",
    "Some examples might make this clearer:\n",
    "\n",
    "- The linear regression algorithm results in a model comprised of a vector of coefficients with specific values.\n",
    "- The decision tree algorithm results in a model comprised of a tree of if-then statements with specific values.\n",
    "- The neural network / backpropagation / gradient descent algorithms together result in a model comprised of a graph structure with vectors or matrices of weights with specific values.\n",
    "\n",
    "> A machine learning model is more challenging for a beginner because there is not a clear analogy with other algorithms in computer science. For example, the sorted list output of a sorting algorithm is not really a model.\n",
    "\n",
    "<mark>The best analogy is to think of the machine learning model as a “program.”</mark>\n",
    "\n",
    "The machine learning model “program” is comprised of both data and a procedure for using the data to make a prediction.\n",
    "\n",
    "For example, consider the linear regression algorithm and resulting model. The model is comprised of a vector of coefficients (data) that are multiplied and summed with a row of new data taken as input in order to make a prediction (prediction procedure).\n",
    "\n",
    "We save the data for the machine learning model for later use.\n",
    "\n",
    "We often use the prediction procedure for the machine learning model provided by a machine learning library. Sometimes we may implement the prediction procedure ourselves as part of our application. This is often straightforward to do given that most prediction procedures are quite simple. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63cb75d-8420-48af-a511-e6c9a45ba555",
   "metadata": {
    "tags": []
   },
   "source": [
    "> In 2017, a Stanford research team under Andrew Ng released a paper on an algorithm that detects pneumonia from chest X-rays. The original paper stated that they used “112,120 frontal-view X-ray images of 30,805 unique patients” and “We randomly split the entire dataset into 80% training, and 20% validation”. This prompted some to question whether there are patient overlaps between the train, validation, and test sets. In case of overlap, this could greatly overestimate the model performance. It was only subsequently that the research team clarified in their paper that there is no overlap. But it was an unnecessary controversy that could have been avoided.\n",
    "\n",
    "> In this paper by Zhu Sun et. al., it was found that only 12% of the 85 sampled recommendation papers published at top-tier conferences use a fixed timestamp to train-test split data. Yitong Ji et. al. reasoned that ignorance of global timeline is inappropriate for evaluating recommender systems and may result in unreasonable scenarios where “future items” are recommended to users.\n",
    "\n",
    "Ethically, it is suggested to divide your dataset into three parts to avoid overfitting and model selection bias called -\n",
    "\n",
    "- Training set (Has to be the largest set)\n",
    "- Cross-Validation set or Development set or Dev set\n",
    "- Testing Set\n",
    "\n",
    "> The test set can be sometimes omitted too. It is meant to get an unbiased estimate of algorithms performance in the real world. People who divide their dataset into just two parts usually call their Dev set the Test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f53e756-d800-43d9-bec9-c21d60d904af",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Splitting data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee0ef10-1456-449e-a61d-1c3be83ce727",
   "metadata": {},
   "source": [
    "#### Training Set:\n",
    "The sample of data used to fit the model, that is the actual subset of the dataset that we use to train the model (estimating the weights and biases in the case of Neural Network). The model observes and learns from this data and optimize its parameters.\n",
    "\n",
    "#### Cross-Validation Set:\n",
    "We select the appropriate model or the degree of the polynomial (if using regression model only) by minimizing the error on the cross-validation set.\n",
    "\n",
    "#### Test set:\n",
    "The sample of data used to provide an unbiased evaluation of a final model fit on the training dataset. It is only used once the model is completely trained using the training and validation sets. Therefore test set is the one used to replicate the type of situation that will be encountered once the model is deployed for real-time use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5f425a-94bf-4dd1-86a0-2cca064109e1",
   "metadata": {},
   "source": [
    "#### How to decide the ratio of splitting the dataset?\n",
    "\n",
    "![](https://miro.medium.com/max/700/1*AE17O-39mBq3PFBalay6-w.png)\n",
    "\n",
    "he answer generally lies in the dataset itself. The proportions are decided according to the size and type (for time series data, splitting techniques are a bit different) of data available with us.\n",
    "\n",
    "- If the size of our dataset is between 100 to 10,00,000, then we split it in the ratio 60:20:20. That is 60% data will go to the Training Set, 20% to the Dev Set and remaining to the Test Set.\n",
    "\n",
    "- If the size of the data set is greater than 1 million then we can split it in something like this 98:1:1 or 99:0.5:0.5\n",
    "\n",
    "The main aim of deciding the splitting ratio is that **all three sets should have the general trend of our original dataset. If our dev set has very little data, then it is possible that we’ll end up selecting some model which is biased towards the trends only present in the dev set. Same is the case with training sets — too little data will bias the model towards some trends found only in that subset of the dataset.**\n",
    "\n",
    "<mark>The models that we deploy are nothing but estimators learning the statistical trends in the data. Therefore, it is important that the data that is being used to learn and that being used to validate or test the model follow as similar statistical distribution as possible. One of the ways to achieve this as perfectly as possible is to select the subsets — here the training set, the dev set and/or the test set — randomly. </mark>For example, suppose that you are working on a face detection project and face training pictures are taken from the web and the dev/test pictures are from users cell phone, then there will be a mismatch between the properties of train set and dev/test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f341280-4a76-46c8-a618-1fb5965992af",
   "metadata": {},
   "source": [
    "#### Question: What problem may arise if we randomly split a dataset that has 99% negative class and 1% positive class?\n",
    "\n",
    "A potential result is that **we have even less or none of the positive class in our training data. Leaving everything to chance is probably not the ideal way to split an imbalanced dataset.**\n",
    "\n",
    "A better way is to **stratify on the class labels. Our trustworthy scikit-learn’s train_test_split has a stratify parameter that allows us to split data in a stratified fashion. Even if we do not have an imbalanced dataset, it is always good practice to stratify on the class labels and other important sub-classes of interest to ensure that our test and training data distributions are similar to each other.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282afb78-e577-49ad-a446-b04b2d443f78",
   "metadata": {},
   "source": [
    "#### Question: In experiments with limited data, what could be a possible model evaluation issue if we perform a simple train-test split?\n",
    "\n",
    "Ensuring that the test and training data distributions are similar to each other can be very challenging with limited data. If we allocate too much data for training, we will then end up with too little test data for good representation and the model results may not be generalizable.\n",
    "\n",
    "A potential solution is **k-fold cross-validation, where the data is split into k subsets (or folds) and the following procedure is performed.**\n",
    "\n",
    "1. Train model using k -1 folds\n",
    "2. Validate model on the remaining fold that was not used for training\n",
    "3. Repeat above two steps for each combination of folds and average the model results\n",
    "\n",
    "![](https://miro.medium.com/max/624/1*IwJZ7tK1W7POeti_XliOyQ.png)\n",
    "\n",
    "This method enables the model to be evaluated on the full variety of data in the dataset to derive an average model result that will more accurately estimate the model performance than evaluating on just a small test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58741256-ce7f-4411-9062-295cd4c62c4b",
   "metadata": {},
   "source": [
    "#### Question: What’s wrong with standardizing on the whole data before doing a train-test split?\n",
    "\n",
    "When we standardize on the whole data before a train-test split, we are “leaking” information of the test data distribution through the mean and standard deviation to the model. This article has a nice experiment that shows how feature engineering before train-test split can impact model evaluation.\n",
    "\n",
    "A more obvious case of feature engineering leakage is when we perform hot deck imputation of missing data using the whole dataset. This may result in test data points being imputed with training data points or vice versa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a235b021-ab95-4b8a-bdd4-a631d07fe46d",
   "metadata": {},
   "source": [
    "#### Question: If there are patient overlaps between the train, validation, and test sets, why might the model performance be greatly overestimated? \n",
    "\n",
    "In most X-ray data sets, the same patient will have multiple X-rays and they are obviously highly correlated. The model could simply end up learning to recognize people (i.e., assign the training data label to the X-ray in the test data for the same patient) rather than detecting diseases, resulting in inflated model performance.\n",
    "\n",
    "> The correct way in this case is to split by the object identifier and not by data points or images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c8dbc6-7ae4-498f-8c23-c129368b8cf7",
   "metadata": {},
   "source": [
    "#### Question: Any issue with randomly splitting a time series data?\n",
    "\n",
    "Yes, when our task is to forecast the future and our model is already shown a piece of that future before prediction.\n",
    "\n",
    "The proper way in the simplest case is to ensure that the test data is chronologically later than the training data.\n",
    "\n",
    "![](https://miro.medium.com/max/531/1*0Fq86Va9e62F8s9dgL72hQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a9914c-94e1-40df-859d-a8241c11db7b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Clean, Transform and Reduce data\n",
    "\n",
    "> Almost is sure that you'll always need to pre-process your data before being able of fitting a model with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ac9ec9-5ea3-430d-b349-20c08f5878c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "![](https://www.researchgate.net/profile/Martin-Andreoni/publication/327183263/figure/fig21/AS:662772148887552@1535028602008/Preprocessing-steps-composed-of-Data-Consolidation-Data-Cleaning-Data-Transformation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf5ba86-e495-4b8a-990d-0dd525f60774",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### The importance of data\n",
    "\n",
    "Data is the most important and must-have food for machine learning. It can be any fact, text, symbols, images, videos, etc., but in unprocessed form. When the data is processed, it is known as information. Machine learning without data is nothing but a bare machine with no soul and no mind. This data makes machines do such amazing tasks, which we have not thought of a few years back in history.\n",
    "\n",
    "Despite having such importance, machines do not understand what data represents. They don’t understand why ‘a’ is ‘a’ and why it is written in this way or why ‘this’ means what it means. Most of us don’t understand the food that we eat. The only thing that we know is that we have to eat, and we do so. We don’t care for backgrounds and foregrounds. Data for machine learning is food. It just consumes it and then learns the relations between different data rather than understanding the data.\n",
    "\n",
    "> So basically, all machines do, is find the relations between the different data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fd3e22-5a24-48d6-b5ce-34d763908a99",
   "metadata": {},
   "source": [
    "#### Types of data\n",
    "\n",
    "Data is crucial for machine learning, and without data, machine learning is not possible. It requires data in one form or the other. Just like we humans need food for our development of mind and then when we get another type of data by visualizing, hearing, etc., and get experience from such data. That data plays a vital role in the type of human we will be in the future.\n",
    "\n",
    "In the same way, **data for machine learning is important to grow its experience and ability to make decisions based on the data fed to it.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa36467-f34c-43fa-82b6-ee1776135687",
   "metadata": {},
   "source": [
    "##### Numerical Data\n",
    "\n",
    "This type of data is in the form of numbers and only numbers. This is a good type of data, and all machine learning models work with data. All other data types need to be translated to this form, and then that data is fed into the machine—the data like 1, 2, age, salary, experience, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b813d0e4-cf9e-4615-b615-e9cd876ce9ea",
   "metadata": {},
   "source": [
    "##### Categorical data Data\n",
    "\n",
    "This is another type of data. Usually, the data which contains characters like text, symbols comes in this category. This type of data is firstly and is very important to convert to numerical form using some techniques. Unless converted, the machine can’t take this data and formulate the relations between input and output data. When dealing with this type of data, it is important to keep this point in mind.\n",
    "\n",
    "> Always remember to convert categorical data into numerical one so machines can understand it mathematically\n",
    "\n",
    "![](https://hackernoon.com/_next/image?url=https%3A%2F%2Fmiro.medium.com%2Fmax%2F700%2F1*lA5BQIc7fiSsGXiqr4V0Qg.jpeg&w=1920&q=75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16b26ae-e408-44ed-9ed8-1e33f9fdb46c",
   "metadata": {},
   "source": [
    "#### How much data should be there.\n",
    "\n",
    "This is also an essential point to consider when dealing with machine learning. How much is an important factor, and keep in mind, we should have sufficient data s.t the machine does not die of starvation and not too much data so that the machine does not become worthless.\n",
    "\n",
    "> **Too little and too much both are bad for machines and also for humans and all beings.**\n",
    "\n",
    "![](https://hackernoon.com/_next/image?url=https%3A%2F%2Fmiro.medium.com%2Fmax%2F700%2F0*aiSPduywHJ2ApWZP.jpg&w=1920&q=75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d1277d-a8d5-4d12-bf82-90ea6dd62d3d",
   "metadata": {},
   "source": [
    "#### The Significance of Data Quality in Making a Successful Machine Learning Model\n",
    "\n",
    "**Data quality ensures data is fit for consumption and meets the needs of data consumers.** Historically individuals did not have data quality tools and had to manually identify data issues. Over the past two years, we have seen the emergence of numerous data quality solutions and believe it is a core component of the modern data stack.\n",
    "\n",
    "To be of high quality, data must be consistent and unambiguous. You can measure data quality through dimensions including accuracy, completeness, consistency, integrity, reasonability, timelines, uniqueness, format, validity, and accessibility.\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://miro.medium.com/max/916/0*Bl-P4P3m3VN2alLC\" width=300/>\n",
    "</center>\n",
    "\n",
    "Data quality is foundational to business’ human and machine decision making. Dirty data can result in incorrect values in dashboards and executive briefings. Importantly, once confidence in the data erodes, teams don’t trust the figures, which can lead to indecision slowing business progress. Additionally, we’ve heard about bad data leading to product development decisions that have caused corporations to lose millions of dollars in engineering effort. Machine-made decisions based on bad data can lead to biased or inaccurate actions.\n",
    "\n",
    "##### A strategy for data quality\n",
    "A modern data-intensive project typically involves data streams, complex ETL processes, post-processing logic, and a range of analytical or cognitive components.\n",
    "\n",
    "The key deliverable in such scenarios is a high-performance data processing pipeline, feeding and maintaining at least one data store. This defines a “data environment,” which then empowers advanced analytical models, real-time decision making, knowledge extraction, and possibly AI applications. The following describes a strategy for ensuring data quality throughout this process.\n",
    "\n",
    "Identify, understand, and document the data sources\n",
    "You need to identify your data sources and, for each one, briefly document the following:\n",
    "\n",
    "1. Type of data contained — for example customer records, web traffic, user documents, activity from a connected device (in an IoT context).\n",
    "\n",
    "2. Type of storage — for instance, is it a flat file, a relational database, a document store, or a stream of events?\n",
    "\n",
    "3. Time frames — how long do we have data for?\n",
    "\n",
    "4. Frequency and types of updates — are you getting deltas, events, updates, aggregated data? All these can significantly impact the design of the pipeline and the ability to identify and handle data quality issues.\n",
    "\n",
    "5. The source of data and involved systems — is data coming from another system? Is it a continuous feed of events or a batch process pulled from another integrated system? Is there manual data entry/ validation involved?\n",
    "\n",
    "6. Known data issues and limitations can help speed up the initial data examination phase — if provided upfront.\n",
    "\n",
    "7. The data models involved in the particular data source — for example, an ER model representing customers, a flat-file structure, an object, a star schema.\n",
    "\n",
    "8. Stakeholders involved — this is very important in order to interpret issues and edge cases and also to validate the overall state of the data, with those having the deepest understanding of the data, the business, and the related processes.\n",
    "\n",
    "##### Start with data profiling\n",
    "\n",
    "Data profiling is the process of describing the data by performing basic descriptive statistical analysis and summarization. The key is to briefly document the findings thus creating a baseline — a reference point to be used for data validation throughout the process.\n",
    "\n",
    "Data profiling depends on the type of the underlying data and the business context, but in a general scenario you should consider the following:\n",
    "\n",
    "1. Identify the key entities, such as customer, user, product, the events involved, such as register, login, purchase, the time frame, the geography, and other key dimensions of your data.\n",
    "\n",
    "2. Select the typical time frame to use for your analysis. This could be a day, week, month, and so forth depending on the business.\n",
    "\n",
    "3. Analyze high-level trends involving the entities and events identified. Generate time series against the major events and the key entities. Identify trends, seasonality, peaks, and try to interpret them in the context of the particular business. Consult the owner of the data and capture/ document these “data stories.”\n",
    "\n",
    "4. Analyze the data. For each of the properties of your key entities perform statistical summarization to capture the shape of the data. For numerical values, you could start with the basics — min, average, max, standard deviation, quartiles — and then possibly visualize the distribution of the data. Having done so, examine the shape of the distribution and figure out if it makes sense to the business. For categorical values, you could summarize the distinct number of values by frequency and, for example, document the top x values explaining z% of the cases.\n",
    "\n",
    "5. Review a few outliers. Having the distribution of the values for a particular property — let’s say, the age of the customer — try to figure out “suspicious” values in the context of the particular business. Select a few of them and retrieve the actual instances of the entities. Then review their profile and activity — of the particular users, in this example — and try to interpret the suspicious values. Consult the owner of the data to advise on these findings.\n",
    "\n",
    "6. Document your results. Create a compact document or report with a clear structure to act as your baseline and data reference. You should append the findings of each of the data sources to this single document — with the same structure, time references, and metadata to ensure easier interpretation.\n",
    "\n",
    "7. Review, interpret, validate. This is the phase where you need input from the data owner to provide an overall interpretation of the data and to explain edge cases, outliers, or other unexpected data patterns. The outcome of the process could be to confirm the state of the data, explain known issues, and register new ones. This is where possible solutions to known data issues can be discussed and/or decided. Also, validation rules can be documented.\n",
    "\n",
    "In an ideal scenario, the data profiling process should be automated. There are several tools allowing quick data profiling by just connecting your data source and going through a quick wizard-like configuration. The output of the process in such scenarios is typically an interactive report enabling easy analysis of the data and sharing of the knowledge with the team.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc4328f-0735-43d6-98d2-ebd9669b3a90",
   "metadata": {},
   "source": [
    "### a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd4c4ad-dd5f-4bcb-a06b-9c2c4d8c7d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
