{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3f7af5c-dccb-4bd6-9e19-a5af276d2fde",
   "metadata": {},
   "source": [
    "# Why to use Scikit-Learn?\n",
    "\n",
    "<center>\n",
    "    <img \n",
    "         src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/Scikit_learn_logo_small.svg/1280px-Scikit_learn_logo_small.svg.png\"\n",
    "         width=250\n",
    "     />\n",
    "</center>\n",
    "\n",
    "- Built on Numpy and Matplotlib.\n",
    "- Many built-in machine learning models.\n",
    "- Allows us to evaluate our own models.\n",
    "- Very well designed API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1592d6-7e3f-4911-be84-060cd2267906",
   "metadata": {},
   "source": [
    "# How will we use it?\n",
    "\n",
    "![](https://raw.githubusercontent.com/mrdbourke/zero-to-mastery-ml/d7c767dd562ce65e73efa23c8e210f6260f678e5/images/sklearn-workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579c59f6-3828-4ef3-bcb6-4731aacc2b98",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"https://images.contentful.com/pqts2v0qq7kz/3pE9qDdlEIOq4Aou0eYEiY/c929368e0fe004ef87733e39a7d728f7/machine_learning_flow--4j88rajonr_s1800x0_q80_noupscale.png\" width=300 />\n",
    "</center>\n",
    "\n",
    "> At the end a model is a function that is used to get the desired output based in the input. The model is how it is obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4cc462-e120-4daa-b840-dd903e711c5a",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63eceb6d-8621-4eec-8f27-1b3909075b2a",
   "metadata": {},
   "source": [
    "## 1. Importing standard libraries \n",
    "\n",
    "For all machine learning projects, you'll often see these libraries (Matplotlib, NumPy and pandas) imported at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24c8e116-8ed2-4507-9759-a04b243e3b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8304455-ccb3-4e73-92b0-591387a4e1b5",
   "metadata": {},
   "source": [
    "## 2. Importing data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebd25a0-e1f6-45c2-a650-51354a171429",
   "metadata": {},
   "source": [
    "We'll use 2 datasets for demonstration purposes.\n",
    "\n",
    "- `heart_disease` - a classification dataset (predicting whether someone has heart disease or not)\n",
    "- `boston_df` - a regression dataset (predicting the median house prices of cities in Boston)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab30d703-166a-4d40-9225-a99eb9a25284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease_raw_df = pd.read_csv(\"./datasets/heart-disease.csv\")\n",
    "heart_disease_raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc20a99-0acd-4477-847e-8a029eaf06bd",
   "metadata": {},
   "source": [
    "## 3. Scikit-Learn Workflow\n",
    "![](https://github.com/mrdbourke/zero-to-mastery-ml/raw/d7c767dd562ce65e73efa23c8e210f6260f678e5/images/sklearn-workflow-title.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f7eaa2-4fad-4559-b055-b58427602812",
   "metadata": {},
   "source": [
    "### I) Getting data ready\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://www.researchgate.net/profile/Nicholas-Gillian/publication/230691317/figure/fig1/AS:669386654375953@1536605623922/A-machine-learning-algorithm-expressed-as-a-function-h-x-with-input-x-output-y-and.png\" width=300 />\n",
    "</center>\n",
    "\n",
    "Three main things we have to do:\n",
    "\n",
    "1. Split the data into features and labels (usually `X` and `y`)\n",
    "2. Filling (a.k.a imputing) or disregarding missing values\n",
    "3. Converting non-numerical values to numerical values (a.k.a feature encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98295bec-0d50-4d32-b381-9ea44c13fae5",
   "metadata": {},
   "source": [
    "#### Split the data into features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f51d0a7-5ac0-456a-8e30-6b9f40fee5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into X(input) & y(output)\n",
    "X = heart_disease_raw_df.drop(\"target\", axis=1) # use all columns except target\n",
    "y = heart_disease_raw_df[\"target\"] # we want to predict y using X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a644cf1-da46-4042-bb42-1ef4cdeb0f6d",
   "metadata": {},
   "source": [
    "#### Split the data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c90d50be-779b-4c4e-961d-5587aa28d186",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Example use case (requires X & y)\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mX\u001b[49m, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.2\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Example use case (requires X & y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acff728e-b646-40f4-b4a6-07d9944cdb7e",
   "metadata": {},
   "source": [
    "### II) Choosing the right model and hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cd4e30-c7b0-4583-ba36-0423485d7506",
   "metadata": {},
   "source": [
    "### RandomForest Explained\n",
    "\n",
    "![](https://www.tibco.com/sites/tibco/files/media_entity/2021-05/random-forest-diagram.svg)\n",
    "\n",
    "> [Link](https://towardsdatascience.com/understanding-random-forest-58381e0602d2#:~:text=The%20random%20forest%20is%20a,that%20of%20any%20individual%20tree.) to an article that explains it in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80aed7e8-f056-4472-b690-d6c6ba2c466d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# standard abbreviation for classifier based on scikit-learn docs\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# We'll keep the default hyperparameters\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999f3656-5728-45bd-9d71-c5af6d820729",
   "metadata": {},
   "source": [
    "### III) Fit the model to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84e73892-d7ed-4dfc-a3e7-7ba2c109360c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9afda904-180a-4243-8fb8-c43ec992dfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Home\\Documents\\Brian\\Develop\\Data Science\\1 - Basics\\Python toolset exercises\\.env\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0. 2. 3. 4.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_label \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Home\\Documents\\Brian\\Develop\\Data Science\\1 - Basics\\Python toolset exercises\\.env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:808\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    788\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    790\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 808\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    810\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    811\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mD:\\Home\\Documents\\Brian\\Develop\\Data Science\\1 - Basics\\Python toolset exercises\\.env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:850\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    848\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    849\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 850\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    853\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32mD:\\Home\\Documents\\Brian\\Develop\\Data Science\\1 - Basics\\Python toolset exercises\\.env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:579\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    578\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 579\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\Home\\Documents\\Brian\\Develop\\Data Science\\1 - Basics\\Python toolset exercises\\.env\\lib\\site-packages\\sklearn\\base.py:566\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 566\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    567\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mD:\\Home\\Documents\\Brian\\Develop\\Data Science\\1 - Basics\\Python toolset exercises\\.env\\lib\\site-packages\\sklearn\\utils\\validation.py:769\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    767\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    768\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 769\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    770\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    771\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    772\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    773\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    774\u001b[0m         )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;66;03m# make sure we actually converted to numeric:\u001b[39;00m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0. 2. 3. 4.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "y_label = clf.predict(np.array([0,2,3,4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358467e4-2ab6-4757-a5e3-a2c707b6777e",
   "metadata": {},
   "source": [
    "> You can only make prediction on inputs that look like the one that your model has learned to predict, in this case is a row in a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "978d00d6-f3b0-4bcb-b248-15cb6555699a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = clf.predict(X_test)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc14bddf-b16a-430b-a057-cb772fcfb0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190    0\n",
       "298    0\n",
       "150    1\n",
       "93     1\n",
       "229    0\n",
       "      ..\n",
       "96     1\n",
       "227    0\n",
       "269    0\n",
       "214    0\n",
       "77     1\n",
       "Name: target, Length: 61, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9df20b1-e00d-42dc-8826-4be2457db018",
   "metadata": {},
   "source": [
    "### IV) Evaluating the model on the training data and the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba792969-3c35-44f8-bdf6-e8d9e7d2b4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbb0865-9f58-4a36-8653-a739baec1807",
   "metadata": {},
   "source": [
    "> It's obvious that it'll be 100% accurate because it's the data the model has learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "737e30e3-379f-4c15-8a94-494213b247b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7868852459016393"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4855690-424c-42f1-bbf6-0f204519b99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.77      0.75        26\n",
      "           1       0.82      0.80      0.81        35\n",
      "\n",
      "    accuracy                           0.79        61\n",
      "   macro avg       0.78      0.78      0.78        61\n",
      "weighted avg       0.79      0.79      0.79        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "84eeaa25-090f-49fb-b654-0919135ac2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20,  6],\n",
       "       [ 7, 28]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c0907c-08f0-4e48-ad7f-5d5330317505",
   "metadata": {},
   "source": [
    "![](https://cdn-images-1.medium.com/max/800/1*R6jP_uvlkcxtQSa264N3Sw.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4a8bb158-3918-4ff2-95ef-ed6037cacd68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7868852459016393"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3126c6de-0b89-4fcc-b515-0a182ff77d8d",
   "metadata": {},
   "source": [
    "### V) Improving a model\n",
    "#### Changing the ammount of n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd8ae895-c0f1-4a68-9f97-470064ffc86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------- 10 estimators ---------------------------------------\n",
      "Model accuracy on test set: 75.41%\n",
      "--------------------------------------- END 10 estimators ---------------------------------------\n",
      "--------------------------------------- 20 estimators ---------------------------------------\n",
      "Model accuracy on test set: 86.89%\n",
      "--------------------------------------- END 20 estimators ---------------------------------------\n",
      "--------------------------------------- 30 estimators ---------------------------------------\n",
      "Model accuracy on test set: 78.69%\n",
      "--------------------------------------- END 30 estimators ---------------------------------------\n",
      "--------------------------------------- 40 estimators ---------------------------------------\n",
      "Model accuracy on test set: 81.97%\n",
      "--------------------------------------- END 40 estimators ---------------------------------------\n",
      "--------------------------------------- 50 estimators ---------------------------------------\n",
      "Model accuracy on test set: 85.25%\n",
      "--------------------------------------- END 50 estimators ---------------------------------------\n",
      "--------------------------------------- 60 estimators ---------------------------------------\n",
      "Model accuracy on test set: 77.05%\n",
      "--------------------------------------- END 60 estimators ---------------------------------------\n",
      "--------------------------------------- 70 estimators ---------------------------------------\n",
      "Model accuracy on test set: 80.33%\n",
      "--------------------------------------- END 70 estimators ---------------------------------------\n",
      "--------------------------------------- 80 estimators ---------------------------------------\n",
      "Model accuracy on test set: 75.41%\n",
      "--------------------------------------- END 80 estimators ---------------------------------------\n",
      "--------------------------------------- 90 estimators ---------------------------------------\n",
      "Model accuracy on test set: 81.97%\n",
      "--------------------------------------- END 90 estimators ---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "for i in range(10,100,10):\n",
    "    print(f\"--------------------------------------- {i} estimators ---------------------------------------\")\n",
    "    clf = RandomForestClassifier(n_estimators=i).fit(X_train, y_train)\n",
    "    print(f\"Model accuracy on test set: {clf.score(X_test, y_test)* 100:.2f}%\")\n",
    "    print(f\"--------------------------------------- END {i} estimators ---------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48755f6f-8e59-45d6-83d2-da19904300dc",
   "metadata": {},
   "source": [
    "### VI) Save a model and load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fafc3af1-bb11-49c3-9753-d66725063eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=20).fit(X_train, y_train)\n",
    "RANDOM_FOREST_MODEL_PATH = \"./Models exports/Section 9/random_forest_model_1.pkl\"\n",
    "pickle.dump(clf, open(RANDOM_FOREST_MODEL_PATH,\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f363495b-9b22-443b-9208-e45335e4623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(RANDOM_FOREST_MODEL_PATH, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4075d0ea-b14b-4e43-be65-b9209cd8e4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8032786885245902"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f2f451-3d90-4d89-9ccd-4b5de7cdeff6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
